{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea7478d1",
   "metadata": {},
   "source": [
    "# Logistic Regression Problem Formulation\n",
    "\n",
    "### 1. Goal\n",
    "> Predict whether a car is **American-made** (`origin = 1`) or **foreign-made** (`origin = 2 or 3`) using its technical specifications.\n",
    "\n",
    "### 2. Problem Statement\n",
    "> We want to classify cars as either American or foreign based on features such as `cylinders`, `displacement`, `horsepower`, `weight`, and `acceleration`. This is a binary classification task where the target variable is derived from the `origin` column.\n",
    "\n",
    "### 3. Target Variable\n",
    "- Original column: `origin`\n",
    "- Transformed binary label:\n",
    "  - `1` → American-made\n",
    "  - `0` → Foreign-made (Europe or Japan)\n",
    "\n",
    "### 4. Input Features\n",
    "- `cylinders`\n",
    "- `displacement`\n",
    "- `horsepower`\n",
    "- `weight`\n",
    "- `acceleration`\n",
    "\n",
    "These reflect that engine size, power, and design choices may differ by region.\n",
    "\n",
    "### 5. Hypotheses\n",
    "- **Null Hypothesis (H₀)**: None of the selected features significantly influence whether a car is American-made. All coefficients are zero.\n",
    "- **Alternative Hypothesis (H₁)**: At least one of the selected features significantly influences the likelihood that a car is American-made.\n",
    "\n",
    "### 6. Example Input\n",
    "```csv\n",
    "cylinders, displacement, horsepower, weight, acceleration\n",
    "4,113,95,2372,15\n",
    "```\n",
    "\n",
    "### 7. Predicted Output\n",
    "```csv\n",
    "0 → Foreign-made\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb9b3c0",
   "metadata": {},
   "source": [
    "## The expected approach involves:\n",
    "\n",
    "1. Formulating the Model: Defining the linear combination of features and the sigmoid function.\n",
    "\n",
    "2. Using Gradient Descent: This is the standard optimization algorithm used to train the Logistic Regression model (just as it is used to train DNNs).\n",
    "\n",
    "3. Using the Sigmoid Function: This is the link function that maps the linear output to a probability between 0 and 1.\n",
    "\n",
    "4. Using the Log-Loss (Cross-Entropy) Function: This is the standard cost function for classification tasks like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0408101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 392 entries, 0 to 397\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   mpg            392 non-null    float64\n",
      " 1   cylinders      392 non-null    int64  \n",
      " 2   displacement   392 non-null    float64\n",
      " 3   horsepower     392 non-null    int64  \n",
      " 4   weight         392 non-null    int64  \n",
      " 5   acceleration   392 non-null    float64\n",
      " 6   model year     392 non-null    int64  \n",
      " 7   origin         392 non-null    int64  \n",
      " 8   car name       392 non-null    object \n",
      " 9   origin_binary  392 non-null    int64  \n",
      "dtypes: float64(3), int64(6), object(1)\n",
      "memory usage: 33.7+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "original_data = pd.read_csv(\"cars.csv\")\n",
    "\n",
    "# Clean the data (Removes the rows with '?')\n",
    "data = original_data[original_data['horsepower'] != '?'].copy()\n",
    "\n",
    "# 2. Convert to numeric (as they were stored as object since pd.read_csv() because of the '?')\n",
    "data['horsepower'] = pd.to_numeric(data['horsepower'])\n",
    "\n",
    "# Create a new binary column based on the rule\n",
    "# This sets the new column to 1 (True) wherever 'origin' is 1\n",
    "# And 0 (False) otherwise. Pandas/NumPy automatically converts True/False to 1/0.\n",
    "data['origin_binary'] = (data['origin'] == 1).astype(int)\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e466294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 274 (0.70)\n",
      "Validation size: 59 (0.15)\n",
      "Test size: 59 (0.15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.000e+00, 9.700e+01, 8.800e+01, 2.100e+03, 1.650e+01],\n",
       "       [6.000e+00, 2.250e+02, 1.000e+02, 3.233e+03, 1.540e+01],\n",
       "       [4.000e+00, 1.400e+02, 7.500e+01, 2.542e+03, 1.700e+01],\n",
       "       ...,\n",
       "       [8.000e+00, 4.000e+02, 1.900e+02, 4.422e+03, 1.250e+01],\n",
       "       [8.000e+00, 3.500e+02, 1.800e+02, 4.499e+03, 1.250e+01],\n",
       "       [4.000e+00, 7.800e+01, 5.200e+01, 1.985e+03, 1.940e+01]],\n",
       "      shape=(274, 5))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'data' DataFrame exists and 'origin_binary' is created\n",
    "feature_cols = ['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration']\n",
    "target_col = 'origin_binary'\n",
    "\n",
    "X = data[feature_cols].values\n",
    "y = data[target_col].values\n",
    "\n",
    "# First Split: Separate out the Test set (15%)\n",
    "# Using train_test_split for automatic shuffling of data before splitting\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=42\n",
    ")\n",
    "\n",
    "# Second Split: Separate the remaining data (X_temp) into Train (70%) and Validation (15%)\n",
    "# Since X_temp is 85% of the original data, 15% of the original data is \n",
    "# approximately (0.15 / 0.85) of X_temp, which is ~0.176.\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=(0.15 / 0.85), random_state=42\n",
    ")\n",
    "\n",
    "# Check sizes (will be close to 70/15/15)\n",
    "print(f\"Train size: {len(X_train)} ({len(X_train)/len(X):.2f})\")\n",
    "print(f\"Validation size: {len(X_val)} ({len(X_val)/len(X):.2f})\")\n",
    "print(f\"Test size: {len(X_test)} ({len(X_test)/len(X):.2f})\")\n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "290635a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply scaling and bias\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np \n",
    "\n",
    "# --- Feature Scaling ---\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 1. Fit the scaler ONLY on the training data.\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# 2. Transform ALL three sets using the training set's statistics.\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff9997e",
   "metadata": {},
   "source": [
    "### Trying to fine tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "243e22d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual iterations: [10]\n",
      "Accuracy: 0.864406779661017\n",
      "Log-loss: 0.2768888609405282\n",
      "ROC AUC: 0.9456521739130435\n",
      "Mean ROC AUC (CV): 0.9434653299916457\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create the logistic regression model\n",
    "model = LogisticRegression(\n",
    "    penalty=None,         # No regularization to match your custom cost\n",
    "    solver='lbfgs',         # Solver that supports no regularization\n",
    "    max_iter=50,         # Matches your iterations\n",
    "    verbose=0,               # Set to 1 if you want logs\n",
    "    tol=1e-2,\n",
    ")\n",
    "\n",
    "# Fit the model to your training data\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(\"Actual iterations:\", model.n_iter_)\n",
    "\n",
    "# Access learned parameters\n",
    "theta_final = model.coef_        # Shape: (1, n_features)\n",
    "bias = model.intercept_          # Shape: (1,)\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score\n",
    "\n",
    "y_val_pred = model.predict(X_val_scaled)\n",
    "y_val_proba = model.predict_proba(X_val_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Log-loss:\", log_loss(y_val, y_val_proba))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_val, y_val_proba[:, 1]))\n",
    "\n",
    "scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='roc_auc')\n",
    "print(\"Mean ROC AUC (CV):\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f17196",
   "metadata": {},
   "source": [
    "### Evaluating on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c462d0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8813559322033898\n",
      "Test Log-loss: 0.26942451373635695\n",
      "Test ROC AUC: 0.9285714285714286\n"
     ]
    }
   ],
   "source": [
    "# Predict on test set\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "y_test_proba = model.predict_proba(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_log_loss = log_loss(y_test, y_test_proba)\n",
    "test_roc_auc = roc_auc_score(y_test, y_test_proba[:, 1])\n",
    "\n",
    "# Print results\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Test Log-loss:\", test_log_loss)\n",
    "print(\"Test ROC AUC:\", test_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3af12881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set        Accuracy   Log-loss        ROC AUC   \n",
      "Train      0.8832     0.2600          0.9502    \n",
      "Val        0.8644     0.2769          0.9457    \n",
      "Test       0.8814     0.2694          0.9286    \n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Set':<10} {'Accuracy':<10} {'Log-loss':<15} {'ROC AUC':<10}\")\n",
    "print(f\"{'Train':<10} {accuracy_score(y_train, model.predict(X_train_scaled)):<10.4f} {log_loss(y_train, model.predict_proba(X_train_scaled)):<15.4f} {roc_auc_score(y_train, model.predict_proba(X_train_scaled)[:, 1]):<10.4f}\")\n",
    "print(f\"{'Val':<10} {accuracy_score(y_val, y_val_pred):<10.4f} {log_loss(y_val, y_val_proba):<15.4f} {roc_auc_score(y_val, y_val_proba[:, 1]):<10.4f}\")\n",
    "print(f\"{'Test':<10} {test_accuracy:<10.4f} {test_log_loss:<15.4f} {test_roc_auc:<10.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cars-machine-learning-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
